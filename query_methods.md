### Query Transformation and Preprocessing Methods
A collection of query transformation and preprocessing methods that can be used to improve the retrieval of documents.

| Method Name | Core Concept | Primary Use Case | Key Paper / Resource |
| :--- | :--- | :--- | :--- |
| **Normalization (Lowercase, Punctuation/Noise Removal)** | Standardizing the text of a query by converting it to lowercase, removing punctuation, and stripping out irrelevant characters or symbols. | To ensure that searches are case-insensitive and not affected by superficial textual variations (e.g., `RAG` matches `rag`). This is a foundational step for almost all search systems. |  |
| **Stop Word Removal** | Removing common and high-frequency words (e.g., "the", "is", "a", "in") that provide little semantic value for retrieval. | Reducing noise and focusing the query on the most meaningful terms, which can improve the precision of keyword-based retrieval systems. |  |
| **Stemming / Lemmatization** | Reducing words to their root or base form. Stemming is a crude heuristic (e.g., "studies" -> "studi"), while lemmatization uses vocabulary and morphological analysis (e.g., "studies" -> "study"). | To match queries with documents that use different forms of the same word. Lemmatization is generally preferred for its linguistic accuracy. | |
| **Multi-Query** | Generates several variations of a single user query to capture different facets and perspectives of the user's intent. The retrieved documents are then processed by retrieval methods (e.g., reranking with a cross-encoder, rag-fusion, unique set of documents) | Overcoming the limitations of distance-based similarity search by broadening the search scope. Ideal for ambiguous or multifaceted queries. | [LangChain Documentation](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever) |
| **Decomposition** | Breaks down a complex, multi-part question into a set of simpler, standalone sub-questions that can be answered individually. | Answering complex questions that require synthesizing information from different parts of a knowledge base. | [Query Decomposition: Understanding the User's Perspective](https://medium.com/inspiredbrilliance/query-decomposition-understanding-the-users-perspective-7dae7522db75) |
| **Step-Back Prompting** | Transforms a specific question into a more general, high-level "step-back" question to retrieve broader, foundational context. | Answering questions that require understanding fundamental principles or a wider context before addressing the specific detail. | [Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](https://arxiv.org/abs/2310.06117) |
| **HyDE** | Generates a hypothetical, ideal document (an "answer") in response to a query and then uses the embedding of this fake document to find real, similar documents. This is essentially a full transformation of the query. Note that when generating the embedding for this fake document, the document encoder should be used instead of the traditional query encoder for user queries! | Bridging the semantic gap between a concise query and a verbose document, improving retrieval relevance, especially in specialized domains. | [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496) |
| **Rewrite-Retrieve-Read** | Utilizes an LLM to rewrite the initial user query into a more optimal version for the retrieval system before fetching documents. | Improving retrieval accuracy by refining poorly phrased, vague, or sub-optimal user questions into queries the retriever can better understand. | [Query Rewriting for Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2305.14283) |
| **ReAct** | Synergizes Reasoning and Acting. The model generates interleaved reasoning steps (thoughts) and actions (e.g., searches) to solve a problem. | For complex tasks requiring dynamic planning and interaction with external tools (like a search engine) to gather information iteratively. | [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) |
| **Chain-of-Note (CoN)** | Reads documents, generates sequential "notes" about them, and then uses these notes to iteratively refine understanding and generate a final answer. | Enhancing comprehension of retrieved documents by encouraging a more thorough, step-by-step analysis before synthesizing a final answer. | [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models](https://arxiv.org/abs/2311.09210) |